{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c963767-388e-46a3-8783-969f6c58015a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from typing import Dict, List, Tuple\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "from statsmodels.formula.api import ols  # type: ignore\n",
    "from statsmodels.stats.anova import anova_lm  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40886b1e-e1b3-48eb-83e7-be0536fd9688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "def load_embeddings(embeddings_file: str) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"Load embeddings from CSV and organize them by column.\n",
    "\n",
    "    Args:\n",
    "        embeddings_file: Path to the CSV file containing embeddings\n",
    "\n",
    "    Returns:\n",
    "        Dictionary where keys are column names and values are numpy arrays\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(embeddings_file)\n",
    "    embedding_cols = [col for col in df.columns if col.endswith(\"_embedding\")]\n",
    "    embeddings_dict = {}\n",
    "\n",
    "    for col in embedding_cols:\n",
    "\n",
    "        def parse_embedding(x):\n",
    "            \"\"\"Convert string representation to numpy array.\"\"\"\n",
    "            if pd.isna(x):\n",
    "                return np.zeros(384, dtype=np.float32)\n",
    "            return np.fromstring(x.strip(\"[]\"), sep=\" \", dtype=np.float32)\n",
    "\n",
    "        embeddings = df[col].apply(parse_embedding).values\n",
    "        embeddings_array = np.vstack(embeddings)\n",
    "        embeddings_dict[col] = embeddings_array\n",
    "\n",
    "    return embeddings_dict\n",
    "\n",
    "\n",
    "def identify_actors_and_reasons(\n",
    "    embeddings_dict: Dict[str, np.ndarray],\n",
    ") -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"Identify actors and reason types from embedding column names.\n",
    "\n",
    "    Args:\n",
    "        embeddings_dict: Dictionary mapping column names to embedding arrays\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (actors, reason_types) sorted lists\n",
    "    \"\"\"\n",
    "    actors = set()\n",
    "    reason_types = set()\n",
    "\n",
    "    for col in embeddings_dict.keys():\n",
    "        if col in [\"selftext_embedding\"]:\n",
    "            continue\n",
    "\n",
    "        if col == \"top_comment_embedding\":\n",
    "            actors.add(\"redditor\")\n",
    "            reason_types.add(\"top_comment\")\n",
    "            continue\n",
    "\n",
    "        parts = col.replace(\"_embedding\", \"\").split(\"_\")\n",
    "\n",
    "        actor = parts[0]\n",
    "        reason = \"_\".join(parts[1:])\n",
    "\n",
    "        actors.add(actor)\n",
    "        reason_types.add(reason)\n",
    "\n",
    "    desired_order = [\n",
    "        \"redditor\",\n",
    "        \"gpt3.5\",\n",
    "        \"gpt4\",\n",
    "        \"claude\",\n",
    "        \"bison\",\n",
    "        \"gemini\",\n",
    "        \"llama\",\n",
    "        \"mistral\",\n",
    "        \"gemma\",\n",
    "    ]\n",
    "    actors_list = list(actors)\n",
    "    actors_known = [a for a in actors_list if a in desired_order]\n",
    "    actors_unknown = sorted([a for a in actors_list if a not in desired_order])\n",
    "    actors_sorted = (\n",
    "        sorted(actors_known, key=lambda a: desired_order.index(a)) + actors_unknown\n",
    "    )\n",
    "\n",
    "    actors = actors_sorted\n",
    "    reason_types = sorted(list(reason_types))\n",
    "\n",
    "    return actors, reason_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc39a52a-c1f6-43d6-a3c4-a2c24e75baa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "def extract_llm_human_similarities_for_anova(\n",
    "    all_embeddings_dict: Dict[str, Dict[str, np.ndarray]],\n",
    "    language_codes: List[str],\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Extract all LLM vs human similarity pairs for ANOVA analysis.\n",
    "\n",
    "    Creates a table with all reasoning comparisons from each model for each scenario,\n",
    "    allowing statistical comparison of how different models and languages compare to humans.\n",
    "    All reasonings from the same model are treated as samples from that model.\n",
    "\n",
    "    Args:\n",
    "        all_embeddings_dict: Dictionary mapping language codes to embedding dictionaries\n",
    "        language_codes: List of language codes to process\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with columns: actor1, actor2, language, similarity, scenario_idx\n",
    "        where actor1 is the model name (e.g. \"claude\"), actor2 is always \"human\"\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for language_code in tqdm(language_codes, desc=\"Processing languages\"):\n",
    "        embeddings_dict = all_embeddings_dict[language_code]\n",
    "        actors, reason_types = identify_actors_and_reasons(embeddings_dict)\n",
    "\n",
    "        # Get human embedding\n",
    "        if \"top_comment_embedding\" not in embeddings_dict:\n",
    "            continue\n",
    "        human_embeddings = embeddings_dict[\"top_comment_embedding\"]\n",
    "        n_scenarios = human_embeddings.shape[0]\n",
    "\n",
    "        # Process each LLM actor\n",
    "        for actor in actors:\n",
    "            if actor == \"redditor\":\n",
    "                continue\n",
    "\n",
    "            # Get all available reasoning types for this actor\n",
    "            for reason_type in reason_types:\n",
    "                col_name = f\"{actor}_{reason_type}_embedding\"\n",
    "                if col_name not in embeddings_dict:\n",
    "                    continue\n",
    "\n",
    "                llm_embeddings = embeddings_dict[col_name]\n",
    "\n",
    "                # Compare each scenario\n",
    "                for scenario_idx in range(n_scenarios):\n",
    "                    llm_emb = llm_embeddings[scenario_idx].reshape(1, -1)\n",
    "                    human_emb = human_embeddings[scenario_idx].reshape(1, -1)\n",
    "\n",
    "                    llm_emb_norm = normalize(llm_emb, norm=\"l2\")\n",
    "                    human_emb_norm = normalize(human_emb, norm=\"l2\")\n",
    "\n",
    "                    similarity = cosine_similarity(llm_emb_norm, human_emb_norm)[0, 0]\n",
    "\n",
    "                    results.append(\n",
    "                        {\n",
    "                            \"actor1\": actor,\n",
    "                            \"actor2\": \"human\",\n",
    "                            \"language\": language_code,\n",
    "                            \"similarity\": float(similarity),\n",
    "                            \"scenario_idx\": scenario_idx,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e79e175-5ad5-4842-ab5b-4a78ed60a235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "all_embeddings = {\n",
    "    \"Base\": load_embeddings(\"../data/embeddings.csv\"),\n",
    "    \"Portuguese\": load_embeddings(\"../data/embeddings_br.csv\"),\n",
    "    \"German\": load_embeddings(\"../data/embeddings_de.csv\"),\n",
    "    \"Spanish\": load_embeddings(\"../data/embeddings_es.csv\"),\n",
    "    \"French\": load_embeddings(\"../data/embeddings_fr.csv\"),\n",
    "}\n",
    "\n",
    "language_codes = [\"Base\", \"Portuguese\", \"German\", \"Spanish\", \"French\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcc3262-6ddf-4c6d-99bf-2536a50aa6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing languages: 100%|██████████| 5/5 [00:42<00:00,  8.57s/it]\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "# Extract all LLM vs human similarities\n",
    "df_anova = extract_llm_human_similarities_for_anova(all_embeddings, language_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b507896-ec48-40cb-98d8-c0136df4c95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "# Save the data\n",
    "output_file = \"../results/anova_data.csv\"\n",
    "df_anova.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ba8485-b231-4b59-bed5-097dad69e0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DESCRIPTIVE STATISTICS ===\n",
      "\n",
      "By Actor (LLM + reasoning type):\n",
      "           count      mean       std       min       25%       50%       75%  \\\n",
      "actor1                                                                         \n",
      "bison    32418.0  0.468642  0.171823 -0.122836  0.353789  0.482966  0.596684   \n",
      "claude   35200.0  0.443907  0.149189 -0.093526  0.344198  0.457664  0.553225   \n",
      "gemini    2782.0  0.420075  0.138107 -0.026329  0.316160  0.429498  0.520325   \n",
      "gemma    56812.0  0.412250  0.147336 -0.123496  0.312816  0.420206  0.518762   \n",
      "gpt3.5   35200.0  0.431731  0.152288 -0.157070  0.327947  0.441166  0.544672   \n",
      "gpt4     24394.0  0.449698  0.161081 -0.112287  0.340416  0.461528  0.566727   \n",
      "llama    35200.0  0.398551  0.169290 -0.193726  0.294246  0.418923  0.522491   \n",
      "mistral  35200.0  0.390742  0.158669 -0.131123  0.283102  0.400584  0.506198   \n",
      "\n",
      "              max  \n",
      "actor1             \n",
      "bison    0.925996  \n",
      "claude   0.884231  \n",
      "gemini   0.769867  \n",
      "gemma    0.841023  \n",
      "gpt3.5   0.874765  \n",
      "gpt4     0.904920  \n",
      "llama    0.852901  \n",
      "mistral  0.856723  \n",
      "\n",
      "By Language:\n",
      "               count      mean       std       min       25%       50%  \\\n",
      "language                                                                 \n",
      "Base        237732.0  0.430962  0.155889 -0.157070  0.325781  0.440278   \n",
      "French        5922.0  0.367728  0.172734 -0.155702  0.292618  0.407512   \n",
      "German        7224.0  0.248170  0.143811 -0.193726  0.165150  0.262624   \n",
      "Portuguese    4620.0  0.472199  0.158918 -0.093318  0.414441  0.504718   \n",
      "Spanish       1708.0  0.440235  0.175706 -0.125831  0.379250  0.476934   \n",
      "\n",
      "                 75%       max  \n",
      "language                        \n",
      "Base        0.544205  0.925996  \n",
      "French      0.485269  0.781536  \n",
      "German      0.342914  0.711157  \n",
      "Portuguese  0.576813  0.814004  \n",
      "Spanish     0.555765  0.820394  \n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\n=== DESCRIPTIVE STATISTICS ===\")\n",
    "print(\"\\nBy Actor (LLM + reasoning type):\")\n",
    "print(df_anova.groupby(\"actor1\")[\"similarity\"].describe())\n",
    "\n",
    "print(\"\\nBy Language:\")\n",
    "print(df_anova.groupby(\"language\")[\"similarity\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba1220d-80be-4069-8ad2-abf12c940be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ONE-WAY ANOVA: Comparing Actors ===\n",
      "F-statistic: 957.5433\n",
      "p-value: 0.0000e+00\n",
      "Result: Significant differences exist between actors (p < 0.05)\n",
      "\n",
      "Statsmodels:\n",
      "                sum_sq        df           F  PR(>F)\n",
      "C(actor1)   166.033028       7.0  957.543295     0.0\n",
      "Residual   6370.970806  257198.0         NaN     NaN\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "# Perform One-Way ANOVA for actors\n",
    "print(\"\\n=== ONE-WAY ANOVA: Comparing Actors ===\")\n",
    "actor_groups = [\n",
    "    group[\"similarity\"].values for name, group in df_anova.groupby(\"actor1\")\n",
    "]\n",
    "f_stat_actor, p_value_actor = stats.f_oneway(*actor_groups)\n",
    "print(f\"F-statistic: {f_stat_actor:.4f}\")\n",
    "print(f\"p-value: {p_value_actor:.4e}\")\n",
    "if p_value_actor < 0.05:\n",
    "    print(\"Result: Significant differences exist between actors (p < 0.05)\")\n",
    "else:\n",
    "    print(\"Result: No significant differences between actors (p >= 0.05)\")\n",
    "\n",
    "print(\"\\nStatsmodels:\")\n",
    "actor_model = ols(\"similarity ~ C(actor1)\", data=df_anova).fit()\n",
    "actor_anova_table = anova_lm(actor_model, typ=2)\n",
    "print(actor_anova_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad53ce70-67c1-4bb4-a810-cc5ba0246cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ONE-WAY ANOVA: Comparing Languages ===\n",
      "F-statistic: 2710.8010\n",
      "p-value: 0.0000e+00\n",
      "Result: Significant differences exist between languages (p < 0.05)\n",
      "\n",
      "Statsmodels:\n",
      "                  sum_sq        df            F  PR(>F)\n",
      "C(language)   264.441706       4.0  2710.801022     0.0\n",
      "Residual     6272.562127  257201.0          NaN     NaN\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "# Perform One-Way ANOVA for languages\n",
    "print(\"\\n=== ONE-WAY ANOVA: Comparing Languages ===\")\n",
    "language_groups = [\n",
    "    group[\"similarity\"].values for name, group in df_anova.groupby(\"language\")\n",
    "]\n",
    "f_stat_lang, p_value_lang = stats.f_oneway(*language_groups)\n",
    "print(f\"F-statistic: {f_stat_lang:.4f}\")\n",
    "print(f\"p-value: {p_value_lang:.4e}\")\n",
    "if p_value_lang < 0.05:\n",
    "    print(\"Result: Significant differences exist between languages (p < 0.05)\")\n",
    "else:\n",
    "    print(\"Result: No significant differences between languages (p >= 0.05)\")\n",
    "\n",
    "print(\"\\nStatsmodels:\")\n",
    "language_model = ols(\"similarity ~ C(language)\", data=df_anova).fit()\n",
    "language_anova_table = anova_lm(language_model, typ=2)\n",
    "print(language_anova_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf97928-e8d0-4864-aa33-9f0448d8e6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TWO-WAY ANOVA: Actor × Language ===\n",
      "                             sum_sq        df           F    PR(>F)\n",
      "C(actor1)              1.515557e+02       7.0  936.781786  0.000000\n",
      "C(language)           -1.579529e-07       4.0   -0.000002  1.000000\n",
      "C(actor1):C(language)  6.679330e-01      28.0    1.032141  0.408768\n",
      "Residual               5.943711e+03  257171.0         NaN       NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielhuf/Documents/PUC/puc-projeto-final/venv/lib/python3.12/site-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 7, but rank is 6\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/Users/danielhuf/Documents/PUC/puc-projeto-final/venv/lib/python3.12/site-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 28, but rank is 8\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "# Two-Way ANOVA using statsmodels (if available)\n",
    "print(\"\\n=== TWO-WAY ANOVA: Actor × Language ===\")\n",
    "model = ols(\n",
    "    \"similarity ~ C(actor1) + C(language) + C(actor1):C(language)\", data=df_anova\n",
    ").fit()\n",
    "anova_table = anova_lm(model, typ=2)\n",
    "print(anova_table)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
