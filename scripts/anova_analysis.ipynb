{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8da1e2-b2e2-4d1b-997a-0539208d7811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.formula.api import ols  # type: ignore\n",
    "from statsmodels.stats.anova import anova_lm  # type: ignore\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from embedding_utils import (\n",
    "    load_embeddings,\n",
    "    extract_llm_human_similarities_for_anova,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bff58c-4156-4b2c-a5bd-ca0fe84600ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "all_embeddings = {\n",
    "    \"Base\": load_embeddings(\"../data/embeddings.csv\"),\n",
    "    \"Portuguese\": load_embeddings(\"../data/embeddings_br.csv\"),\n",
    "    \"German\": load_embeddings(\"../data/embeddings_de.csv\"),\n",
    "    \"Spanish\": load_embeddings(\"../data/embeddings_es.csv\"),\n",
    "    \"French\": load_embeddings(\"../data/embeddings_fr.csv\"),\n",
    "}\n",
    "\n",
    "language_codes = [\"Base\", \"Portuguese\", \"German\", \"Spanish\", \"French\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b263aae6-562e-45d4-8678-31c1a246178a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing languages: 100%|██████████| 5/5 [00:42<00:00,  8.56s/it]\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "df_anova = extract_llm_human_similarities_for_anova(all_embeddings, language_codes)\n",
    "output_file = \"../results/anova_data.csv\"\n",
    "df_anova.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1ee3d9-fc13-47a1-ab79-fc408f0f94d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== POST-HOC TEST: Tukey's HSD ===\n",
      "            group1             group2  meandiff  p-adj   lower   upper  reject\n",
      "        bison_Base        claude_Base   -0.0237 0.0000 -0.0293 -0.0181    True\n",
      "        bison_Base         gemma_Base   -0.0540 0.0000 -0.0591 -0.0489    True\n",
      "        bison_Base        gpt3.5_Base   -0.0365 0.0000 -0.0422 -0.0309    True\n",
      "        bison_Base          gpt4_Base   -0.0158 0.0000 -0.0223 -0.0093    True\n",
      "        bison_Base         llama_Base   -0.0480 0.0000 -0.0535 -0.0424    True\n",
      "        bison_Base       mistral_Base   -0.0676 0.0000 -0.0732 -0.0620    True\n",
      "       claude_Base      claude_French    0.0226 0.0000  0.0078  0.0375    True\n",
      "       claude_Base      claude_German   -0.1352 0.0000 -0.1501 -0.1202    True\n",
      "       claude_Base  claude_Portuguese    0.0980 0.0000  0.0796  0.1163    True\n",
      "       claude_Base     claude_Spanish    0.0828 0.0000  0.0541  0.1114    True\n",
      "       claude_Base         gemma_Base   -0.0303 0.0000 -0.0349 -0.0256    True\n",
      "       claude_Base        gpt3.5_Base   -0.0128 0.0000 -0.0180 -0.0075    True\n",
      "       claude_Base          gpt4_Base    0.0079 0.0000  0.0018  0.0141    True\n",
      "       claude_Base         llama_Base   -0.0242 0.0000 -0.0294 -0.0191    True\n",
      "       claude_Base       mistral_Base   -0.0439 0.0000 -0.0491 -0.0387    True\n",
      "     claude_French      claude_German   -0.1578 0.0000 -0.1782 -0.1375    True\n",
      "     claude_French  claude_Portuguese    0.0753 0.0000  0.0524  0.0983    True\n",
      "     claude_French     claude_Spanish    0.0601 0.0000  0.0284  0.0918    True\n",
      "     claude_French      gemini_French   -0.0153 0.2265 -0.0357  0.0051   False\n",
      "     claude_French       gemma_French   -0.0772 0.0000 -0.0977 -0.0566    True\n",
      "     claude_French      gpt3.5_French   -0.0194 0.0129 -0.0398  0.0011   False\n",
      "     claude_French        gpt4_French   -0.0140 0.4626 -0.0346  0.0067   False\n",
      "     claude_French       llama_French   -0.3854 0.0000 -0.4072 -0.3636    True\n",
      "     claude_French     mistral_French   -0.1876 0.0000 -0.2178 -0.1574    True\n",
      "     claude_German  claude_Portuguese    0.2331 0.0000  0.2101  0.2562    True\n",
      "     claude_German     claude_Spanish    0.2179 0.0000  0.1861  0.2497    True\n",
      "     claude_German      gemini_German   -0.0073 0.9999 -0.0277  0.0130   False\n",
      "     claude_German       gemma_German   -0.0283 0.0000 -0.0479 -0.0087    True\n",
      "     claude_German      gpt3.5_German    0.0077 0.9996 -0.0127  0.0282   False\n",
      "     claude_German        gpt4_German   -0.0007 1.0000 -0.0213  0.0199   False\n",
      "     claude_German       llama_German   -0.2731 0.0000 -0.2917 -0.2545    True\n",
      "     claude_German     mistral_German   -0.1293 0.0000 -0.1530 -0.1055    True\n",
      " claude_Portuguese     claude_Spanish   -0.0152 0.9869 -0.0487  0.0182   False\n",
      " claude_Portuguese  gemini_Portuguese   -0.0136 0.9001 -0.0389  0.0116   False\n",
      " claude_Portuguese   gemma_Portuguese   -0.0995 0.0000 -0.1234 -0.0755    True\n",
      " claude_Portuguese  gpt3.5_Portuguese   -0.0078 1.0000 -0.0326  0.0170   False\n",
      " claude_Portuguese    gpt4_Portuguese   -0.0056 1.0000 -0.0304  0.0193   False\n",
      " claude_Portuguese   llama_Portuguese   -0.1883 0.0000 -0.2293 -0.1474    True\n",
      " claude_Portuguese mistral_Portuguese   -0.1800 0.0000 -0.2183 -0.1418    True\n",
      "    claude_Spanish     gemini_Spanish   -0.0170 0.9937 -0.0561  0.0221   False\n",
      "    claude_Spanish      gemma_Spanish   -0.1032 0.0000 -0.1439 -0.0625    True\n",
      "    claude_Spanish     gpt3.5_Spanish   -0.0020 1.0000 -0.0420  0.0379   False\n",
      "    claude_Spanish       gpt4_Spanish   -0.0124 1.0000 -0.0523  0.0275   False\n",
      "    claude_Spanish      llama_Spanish   -0.3234 0.0000 -0.3907 -0.2561    True\n",
      "    claude_Spanish    mistral_Spanish   -0.1541 0.0000 -0.2153 -0.0928    True\n",
      "     gemini_French      gemini_German   -0.1498 0.0000 -0.1702 -0.1295    True\n",
      "     gemini_French  gemini_Portuguese    0.0770 0.0000  0.0540  0.1000    True\n",
      "     gemini_French     gemini_Spanish    0.0584 0.0000  0.0276  0.0893    True\n",
      "     gemini_French       gemma_French   -0.0619 0.0000 -0.0826 -0.0412    True\n",
      "     gemini_French      gpt3.5_French   -0.0041 1.0000 -0.0246  0.0165   False\n",
      "     gemini_French        gpt4_French    0.0013 1.0000 -0.0194  0.0221   False\n",
      "     gemini_French       llama_French   -0.3701 0.0000 -0.3920 -0.3482    True\n",
      "     gemini_French     mistral_French   -0.1723 0.0000 -0.2026 -0.1420    True\n",
      "     gemini_German  gemini_Portuguese    0.2268 0.0000  0.2040  0.2497    True\n",
      "     gemini_German     gemini_Spanish    0.2083 0.0000  0.1775  0.2390    True\n",
      "     gemini_German       gemma_German   -0.0210 0.0010 -0.0404 -0.0016    True\n",
      "     gemini_German      gpt3.5_German    0.0151 0.2505 -0.0052  0.0353   False\n",
      "     gemini_German        gpt4_German    0.0066 1.0000 -0.0139  0.0270   False\n",
      "     gemini_German       llama_German   -0.2658 0.0000 -0.2843 -0.2474    True\n",
      "     gemini_German     mistral_German   -0.1220 0.0000 -0.1456 -0.0983    True\n",
      " gemini_Portuguese     gemini_Spanish   -0.0186 0.8118 -0.0511  0.0139   False\n",
      " gemini_Portuguese   gemma_Portuguese   -0.0859 0.0000 -0.1097 -0.0620    True\n",
      " gemini_Portuguese  gpt3.5_Portuguese    0.0058 1.0000 -0.0189  0.0306   False\n",
      " gemini_Portuguese    gpt4_Portuguese    0.0080 1.0000 -0.0168  0.0328   False\n",
      " gemini_Portuguese   llama_Portuguese   -0.1747 0.0000 -0.2157 -0.1338    True\n",
      " gemini_Portuguese mistral_Portuguese   -0.1664 0.0000 -0.2046 -0.1282    True\n",
      "    gemini_Spanish      gemma_Spanish   -0.0862 0.0000 -0.1262 -0.0462    True\n",
      "    gemini_Spanish     gpt3.5_Spanish    0.0150 0.9994 -0.0242  0.0542   False\n",
      "    gemini_Spanish       gpt4_Spanish    0.0046 1.0000 -0.0346  0.0438   False\n",
      "    gemini_Spanish      llama_Spanish   -0.3064 0.0000 -0.3733 -0.2396    True\n",
      "    gemini_Spanish    mistral_Spanish   -0.1371 0.0000 -0.1979 -0.0763    True\n",
      "        gemma_Base       gemma_French   -0.0243 0.0000 -0.0393 -0.0092    True\n",
      "        gemma_Base       gemma_German   -0.1332 0.0000 -0.1467 -0.1197    True\n",
      "        gemma_Base   gemma_Portuguese    0.0288 0.0000  0.0126  0.0449    True\n",
      "        gemma_Base      gemma_Spanish    0.0098 1.0000 -0.0200  0.0396   False\n",
      "        gemma_Base        gpt3.5_Base    0.0175 0.0000  0.0128  0.0222    True\n",
      "        gemma_Base          gpt4_Base    0.0382 0.0000  0.0325  0.0439    True\n",
      "        gemma_Base         llama_Base    0.0060 0.0000  0.0015  0.0106    True\n",
      "        gemma_Base       mistral_Base   -0.0136 0.0000 -0.0183 -0.0090    True\n",
      "      gemma_French       gemma_German   -0.1090 0.0000 -0.1288 -0.0892    True\n",
      "      gemma_French   gemma_Portuguese    0.0530 0.0000  0.0313  0.0747    True\n",
      "      gemma_French      gemma_Spanish    0.0341 0.0028  0.0010  0.0671    True\n",
      "      gemma_French      gpt3.5_French    0.0578 0.0000  0.0371  0.0785    True\n",
      "      gemma_French        gpt4_French    0.0632 0.0000  0.0422  0.0842    True\n",
      "      gemma_French       llama_French   -0.3083 0.0000 -0.3303 -0.2862    True\n",
      "      gemma_French     mistral_French   -0.1105 0.0000 -0.1409 -0.0800    True\n",
      "      gemma_German   gemma_Portuguese    0.1620 0.0000  0.1413  0.1826    True\n",
      "      gemma_German      gemma_Spanish    0.1430 0.0000  0.1106  0.1754    True\n",
      "      gemma_German      gpt3.5_German    0.0360 0.0000  0.0165  0.0555    True\n",
      "      gemma_German        gpt4_German    0.0276 0.0000  0.0079  0.0473    True\n",
      "      gemma_German       llama_German   -0.2448 0.0000 -0.2624 -0.2272    True\n",
      "      gemma_German     mistral_German   -0.1010 0.0000 -0.1240 -0.0780    True\n",
      "  gemma_Portuguese      gemma_Spanish   -0.0189 0.8265 -0.0525  0.0146   False\n",
      "  gemma_Portuguese  gpt3.5_Portuguese    0.0917 0.0000  0.0683  0.1151    True\n",
      "  gemma_Portuguese    gpt4_Portuguese    0.0939 0.0000  0.0704  0.1173    True\n",
      "  gemma_Portuguese   llama_Portuguese   -0.0889 0.0000 -0.1290 -0.0487    True\n",
      "  gemma_Portuguese mistral_Portuguese   -0.0805 0.0000 -0.1179 -0.0432    True\n",
      "     gemma_Spanish     gpt3.5_Spanish    0.1012 0.0000  0.0603  0.1420    True\n",
      "     gemma_Spanish       gpt4_Spanish    0.0908 0.0000  0.0500  0.1316    True\n",
      "     gemma_Spanish      llama_Spanish   -0.2202 0.0000 -0.2880 -0.1524    True\n",
      "     gemma_Spanish    mistral_Spanish   -0.0509 0.0886 -0.1127  0.0110   False\n",
      "       gpt3.5_Base      gpt3.5_French    0.0161 0.0013  0.0010  0.0311    True\n",
      "       gpt3.5_Base      gpt3.5_German   -0.1146 0.0000 -0.1295 -0.0997    True\n",
      "       gpt3.5_Base  gpt3.5_Portuguese    0.1030 0.0000  0.0853  0.1206    True\n",
      "       gpt3.5_Base     gpt3.5_Spanish    0.0935 0.0000  0.0647  0.1224    True\n",
      "       gpt3.5_Base          gpt4_Base    0.0207 0.0000  0.0145  0.0269    True\n",
      "       gpt3.5_Base         llama_Base   -0.0114 0.0000 -0.0167 -0.0062    True\n",
      "       gpt3.5_Base       mistral_Base   -0.0311 0.0000 -0.0364 -0.0258    True\n",
      "     gpt3.5_French      gpt3.5_German   -0.1307 0.0000 -0.1512 -0.1103    True\n",
      "     gpt3.5_French  gpt3.5_Portuguese    0.0869 0.0000  0.0644  0.1094    True\n",
      "     gpt3.5_French     gpt3.5_Spanish    0.0775 0.0000  0.0455  0.1094    True\n",
      "     gpt3.5_French        gpt4_French    0.0054 1.0000 -0.0154  0.0262   False\n",
      "     gpt3.5_French       llama_French   -0.3661 0.0000 -0.3880 -0.3441    True\n",
      "     gpt3.5_French     mistral_French   -0.1683 0.0000 -0.1986 -0.1379    True\n",
      "     gpt3.5_German  gpt3.5_Portuguese    0.2176 0.0000  0.1952  0.2400    True\n",
      "     gpt3.5_German     gpt3.5_Spanish    0.2082 0.0000  0.1763  0.2401    True\n",
      "     gpt3.5_German        gpt4_German   -0.0085 0.9979 -0.0290  0.0121   False\n",
      "     gpt3.5_German       llama_German   -0.2809 0.0000 -0.2994 -0.2624    True\n",
      "     gpt3.5_German     mistral_German   -0.1370 0.0000 -0.1607 -0.1133    True\n",
      " gpt3.5_Portuguese     gpt3.5_Spanish   -0.0095 1.0000 -0.0427  0.0238   False\n",
      " gpt3.5_Portuguese    gpt4_Portuguese    0.0022 1.0000 -0.0222  0.0265   False\n",
      " gpt3.5_Portuguese   llama_Portuguese   -0.1806 0.0000 -0.2213 -0.1399    True\n",
      " gpt3.5_Portuguese mistral_Portuguese   -0.1722 0.0000 -0.2102 -0.1343    True\n",
      "    gpt3.5_Spanish       gpt4_Spanish   -0.0104 1.0000 -0.0504  0.0297   False\n",
      "    gpt3.5_Spanish      llama_Spanish   -0.3214 0.0000 -0.3887 -0.2540    True\n",
      "    gpt3.5_Spanish    mistral_Spanish   -0.1520 0.0000 -0.2134 -0.0907    True\n",
      "         gpt4_Base        gpt4_French    0.0008 1.0000 -0.0149  0.0164   False\n",
      "         gpt4_Base        gpt4_German   -0.1438 0.0000 -0.1593 -0.1284    True\n",
      "         gpt4_Base    gpt4_Portuguese    0.0844 0.0000  0.0665  0.1024    True\n",
      "         gpt4_Base       gpt4_Spanish    0.0624 0.0000  0.0335  0.0914    True\n",
      "         gpt4_Base         llama_Base   -0.0322 0.0000 -0.0383 -0.0261    True\n",
      "         gpt4_Base       mistral_Base   -0.0518 0.0000 -0.0580 -0.0457    True\n",
      "       gpt4_French        gpt4_German   -0.1446 0.0000 -0.1655 -0.1237    True\n",
      "       gpt4_French    gpt4_Portuguese    0.0837 0.0000  0.0609  0.1065    True\n",
      "       gpt4_French       gpt4_Spanish    0.0617 0.0000  0.0296  0.0938    True\n",
      "       gpt4_French       llama_French   -0.3715 0.0000 -0.3936 -0.3493    True\n",
      "       gpt4_French     mistral_French   -0.1737 0.0000 -0.2041 -0.1432    True\n",
      "       gpt4_German    gpt4_Portuguese    0.2283 0.0000  0.2056  0.2509    True\n",
      "       gpt4_German       gpt4_Spanish    0.2063 0.0000  0.1743  0.2383    True\n",
      "       gpt4_German       llama_German   -0.2724 0.0000 -0.2911 -0.2537    True\n",
      "       gpt4_German     mistral_German   -0.1285 0.0000 -0.1524 -0.1047    True\n",
      "   gpt4_Portuguese       gpt4_Spanish   -0.0220 0.4955 -0.0552  0.0112   False\n",
      "   gpt4_Portuguese   llama_Portuguese   -0.1828 0.0000 -0.2235 -0.1421    True\n",
      "   gpt4_Portuguese mistral_Portuguese   -0.1744 0.0000 -0.2124 -0.1365    True\n",
      "      gpt4_Spanish      llama_Spanish   -0.3110 0.0000 -0.3783 -0.2437    True\n",
      "      gpt4_Spanish    mistral_Spanish   -0.1417 0.0000 -0.2030 -0.0804    True\n",
      "        llama_Base       llama_French   -0.3385 0.0000 -0.3554 -0.3217    True\n",
      "        llama_Base       llama_German   -0.3841 0.0000 -0.3963 -0.3719    True\n",
      "        llama_Base   llama_Portuguese   -0.0662 0.0000 -0.1033 -0.0290    True\n",
      "        llama_Base      llama_Spanish   -0.2164 0.0000 -0.2779 -0.1549    True\n",
      "        llama_Base       mistral_Base   -0.0197 0.0000 -0.0249 -0.0145    True\n",
      "      llama_French       llama_German   -0.0455 0.0000 -0.0657 -0.0254    True\n",
      "      llama_French   llama_Portuguese    0.2724 0.0000  0.2320  0.3128    True\n",
      "      llama_French      llama_Spanish    0.1221 0.0000  0.0587  0.1856    True\n",
      "      llama_French     mistral_French    0.1978 0.0000  0.1665  0.2290    True\n",
      "      llama_German   llama_Portuguese    0.3179 0.0000  0.2792  0.3566    True\n",
      "      llama_German      llama_Spanish    0.1677 0.0000  0.1052  0.2301    True\n",
      "      llama_German     mistral_German    0.1439 0.0000  0.1217  0.1661    True\n",
      "  llama_Portuguese      llama_Spanish   -0.1503 0.0000 -0.2215 -0.0790    True\n",
      "  llama_Portuguese mistral_Portuguese    0.0083 1.0000 -0.0416  0.0583   False\n",
      "     llama_Spanish    mistral_Spanish    0.1693 0.0000  0.0879  0.2508    True\n",
      "      mistral_Base     mistral_French   -0.1211 0.0000 -0.1480 -0.0942    True\n",
      "      mistral_Base     mistral_German   -0.2205 0.0000 -0.2398 -0.2013    True\n",
      "      mistral_Base mistral_Portuguese   -0.0381 0.0005 -0.0722 -0.0041    True\n",
      "      mistral_Base    mistral_Spanish   -0.0274 0.9455 -0.0822  0.0274   False\n",
      "    mistral_French     mistral_German   -0.0995 0.0000 -0.1320 -0.0669    True\n",
      "    mistral_French mistral_Portuguese    0.0829 0.0000  0.0400  0.1259    True\n",
      "    mistral_French    mistral_Spanish    0.0937 0.0000  0.0331  0.1543    True\n",
      "    mistral_German mistral_Portuguese    0.1824 0.0000  0.1437  0.2211    True\n",
      "    mistral_German    mistral_Spanish    0.1931 0.0000  0.1354  0.2509    True\n",
      "mistral_Portuguese    mistral_Spanish    0.0107 1.0000 -0.0533  0.0747   False\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "print(\"\\n=== POST-HOC TEST: Tukey's HSD ===\")\n",
    "tukey_results = pairwise_tukeyhsd(\n",
    "    df_anova[\"similarity\"],\n",
    "    df_anova[\"actor1\"] + \"_\" + df_anova[\"language\"],\n",
    "    alpha=0.005,\n",
    "    use_var=\"unequal\",\n",
    ")\n",
    "\n",
    "tukey_df = pd.DataFrame(\n",
    "    tukey_results._results_table.data[1:],  # type: ignore[attr-defined]\n",
    "    columns=tukey_results._results_table.data[0],  # type: ignore[attr-defined]\n",
    ")\n",
    "tukey_df[[\"model1\", \"language1\"]] = tukey_df[\"group1\"].str.split(\"_\", n=1, expand=True)\n",
    "tukey_df[[\"model2\", \"language2\"]] = tukey_df[\"group2\"].str.split(\"_\", n=1, expand=True)\n",
    "filtered_tukey = tukey_df[\n",
    "    (tukey_df[\"model1\"] == tukey_df[\"model2\"])\n",
    "    | (tukey_df[\"language1\"] == tukey_df[\"language2\"])\n",
    "]\n",
    "print(\n",
    "    filtered_tukey[\n",
    "        [\"group1\", \"group2\", \"meandiff\", \"p-adj\", \"lower\", \"upper\", \"reject\"]\n",
    "    ].to_string(index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5430644b-1e44-4c63-acb9-95965ad23877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DESCRIPTIVE STATISTICS ===\n",
      "\n",
      "By Actor (LLM + reasoning type):\n",
      "           count      mean       std       min       25%       50%       75%  \\\n",
      "actor1                                                                         \n",
      "bison    32418.0  0.468642  0.171823 -0.122836  0.353789  0.482966  0.596684   \n",
      "claude   35200.0  0.443907  0.149189 -0.093526  0.344198  0.457664  0.553225   \n",
      "gemini    2782.0  0.420075  0.138107 -0.026329  0.316160  0.429498  0.520325   \n",
      "gemma    56812.0  0.412250  0.147336 -0.123496  0.312816  0.420206  0.518762   \n",
      "gpt3.5   35200.0  0.431731  0.152288 -0.157070  0.327947  0.441166  0.544672   \n",
      "gpt4     24394.0  0.449698  0.161081 -0.112287  0.340416  0.461528  0.566727   \n",
      "llama    35200.0  0.398551  0.169290 -0.193726  0.294246  0.418923  0.522491   \n",
      "mistral  35200.0  0.390742  0.158669 -0.131123  0.283102  0.400584  0.506198   \n",
      "\n",
      "              max  \n",
      "actor1             \n",
      "bison    0.925996  \n",
      "claude   0.884231  \n",
      "gemini   0.769867  \n",
      "gemma    0.841023  \n",
      "gpt3.5   0.874765  \n",
      "gpt4     0.904920  \n",
      "llama    0.852901  \n",
      "mistral  0.856723  \n",
      "\n",
      "By Language:\n",
      "               count      mean       std       min       25%       50%  \\\n",
      "language                                                                 \n",
      "Base        237732.0  0.430962  0.155889 -0.157070  0.325781  0.440278   \n",
      "French        5922.0  0.367728  0.172734 -0.155702  0.292618  0.407512   \n",
      "German        7224.0  0.248170  0.143811 -0.193726  0.165150  0.262624   \n",
      "Portuguese    4620.0  0.472199  0.158918 -0.093318  0.414441  0.504718   \n",
      "Spanish       1708.0  0.440235  0.175706 -0.125831  0.379250  0.476934   \n",
      "\n",
      "                 75%       max  \n",
      "language                        \n",
      "Base        0.544205  0.925996  \n",
      "French      0.485269  0.781536  \n",
      "German      0.342914  0.711157  \n",
      "Portuguese  0.576813  0.814004  \n",
      "Spanish     0.555765  0.820394  \n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "print(\"\\n=== DESCRIPTIVE STATISTICS ===\")\n",
    "print(\"\\nBy Actor (LLM + reasoning type):\")\n",
    "print(df_anova.groupby(\"actor1\")[\"similarity\"].describe())\n",
    "\n",
    "print(\"\\nBy Language:\")\n",
    "print(df_anova.groupby(\"language\")[\"similarity\"].describe())\n",
    "\n",
    "# # %%\n",
    "# print(\"\\n=== ONE-WAY ANOVA: Comparing Actors ===\")\n",
    "# actor_model = ols(\"similarity ~ C(actor1)\", data=df_anova).fit()\n",
    "# actor_anova_table = anova_lm(actor_model, typ=2)\n",
    "# print(actor_anova_table)\n",
    "\n",
    "# # %%\n",
    "# print(\"\\n=== ONE-WAY ANOVA: Comparing Languages ===\")\n",
    "# language_model = ols(\"similarity ~ C(language)\", data=df_anova).fit()\n",
    "# language_anova_table = anova_lm(language_model, typ=2)\n",
    "# print(language_anova_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497d9eae-b6c8-4a46-8d5c-ea61be25d150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TWO-WAY ANOVA: Actor × Language ===\n",
      "                            sum_sq        df            F  PR(>F)\n",
      "C(actor1)               102.718378       5.0   919.657495     0.0\n",
      "C(language)             243.908706       4.0  2729.702238     0.0\n",
      "C(actor1):C(language)   158.380327      20.0   354.502420     0.0\n",
      "Residual               4958.588359  221976.0          NaN     NaN\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "df_anova = df_anova[\n",
    "    ~df_anova[\"actor1\"].isin([\"gemini\", \"bison\"])\n",
    "]  # Remove Gemini and Bison from analysis\n",
    "\n",
    "print(\"\\n=== TWO-WAY ANOVA: Actor × Language ===\")\n",
    "model = ols(\"similarity ~ C(actor1) * C(language)\", data=df_anova).fit()\n",
    "anova_table = anova_lm(model, typ=2)\n",
    "print(anova_table)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
