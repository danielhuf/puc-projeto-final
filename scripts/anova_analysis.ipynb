{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adeca69-a573-4b05-874e-d6b064c64349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from typing import Dict, List, Tuple\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "from statsmodels.formula.api import ols  # type: ignore\n",
    "from statsmodels.stats.anova import anova_lm  # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c2f551-3586-4224-abf2-c4a60bcdc060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "def load_embeddings(embeddings_file: str) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"Load embeddings from CSV and organize them by column.\n",
    "\n",
    "    Args:\n",
    "        embeddings_file: Path to the CSV file containing embeddings\n",
    "\n",
    "    Returns:\n",
    "        Dictionary where keys are column names and values are numpy arrays\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(embeddings_file)\n",
    "    embedding_cols = [col for col in df.columns if col.endswith(\"_embedding\")]\n",
    "    embeddings_dict = {}\n",
    "\n",
    "    for col in embedding_cols:\n",
    "\n",
    "        def parse_embedding(x):\n",
    "            \"\"\"Convert string representation to numpy array.\"\"\"\n",
    "            if pd.isna(x):\n",
    "                return np.zeros(384, dtype=np.float32)\n",
    "            return np.fromstring(x.strip(\"[]\"), sep=\" \", dtype=np.float32)\n",
    "\n",
    "        embeddings = df[col].apply(parse_embedding).values\n",
    "        embeddings_array = np.vstack(embeddings)\n",
    "        embeddings_dict[col] = embeddings_array\n",
    "\n",
    "    return embeddings_dict\n",
    "\n",
    "\n",
    "def identify_actors_and_reasons(\n",
    "    embeddings_dict: Dict[str, np.ndarray],\n",
    ") -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"Identify actors and reason types from embedding column names.\n",
    "\n",
    "    Args:\n",
    "        embeddings_dict: Dictionary mapping column names to embedding arrays\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (actors, reason_types) sorted lists\n",
    "    \"\"\"\n",
    "    actors = set()\n",
    "    reason_types = set()\n",
    "\n",
    "    for col in embeddings_dict.keys():\n",
    "        if col in [\"selftext_embedding\"]:\n",
    "            continue\n",
    "\n",
    "        if col == \"top_comment_embedding\":\n",
    "            actors.add(\"redditor\")\n",
    "            reason_types.add(\"top_comment\")\n",
    "            continue\n",
    "\n",
    "        parts = col.replace(\"_embedding\", \"\").split(\"_\")\n",
    "\n",
    "        actor = parts[0]\n",
    "        reason = \"_\".join(parts[1:])\n",
    "\n",
    "        actors.add(actor)\n",
    "        reason_types.add(reason)\n",
    "\n",
    "    desired_order = [\n",
    "        \"redditor\",\n",
    "        \"gpt3.5\",\n",
    "        \"gpt4\",\n",
    "        \"claude\",\n",
    "        \"bison\",\n",
    "        \"gemini\",\n",
    "        \"llama\",\n",
    "        \"mistral\",\n",
    "        \"gemma\",\n",
    "    ]\n",
    "    actors_list = list(actors)\n",
    "    actors_known = [a for a in actors_list if a in desired_order]\n",
    "    actors_unknown = sorted([a for a in actors_list if a not in desired_order])\n",
    "    actors_sorted = (\n",
    "        sorted(actors_known, key=lambda a: desired_order.index(a)) + actors_unknown\n",
    "    )\n",
    "\n",
    "    actors = actors_sorted\n",
    "    reason_types = sorted(list(reason_types))\n",
    "\n",
    "    return actors, reason_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d2b806-215e-4b06-b463-4826c579c3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "def extract_llm_human_similarities_for_anova(\n",
    "    all_embeddings_dict: Dict[str, Dict[str, np.ndarray]],\n",
    "    language_codes: List[str],\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Extract all LLM vs human similarity pairs for ANOVA analysis.\n",
    "\n",
    "    Creates a table with individual reasoning comparisons (not averaged) for each scenario,\n",
    "    allowing statistical comparison of how different models and languages compare to humans.\n",
    "\n",
    "    Args:\n",
    "        all_embeddings_dict: Dictionary mapping language codes to embedding dictionaries\n",
    "        language_codes: List of language codes to process\n",
    "\n",
    "    Returns:\n",
    "        DataFrame with columns: actor1, actor2, language, similarity\n",
    "        where actor1 is like \"claude_reason_2\", actor2 is always \"human\"\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for language_code in tqdm(language_codes, desc=\"Processing languages\"):\n",
    "        embeddings_dict = all_embeddings_dict[language_code]\n",
    "        actors, reason_types = identify_actors_and_reasons(embeddings_dict)\n",
    "\n",
    "        # Get human embedding\n",
    "        if \"top_comment_embedding\" not in embeddings_dict:\n",
    "            continue\n",
    "        human_embeddings = embeddings_dict[\"top_comment_embedding\"]\n",
    "        n_scenarios = human_embeddings.shape[0]\n",
    "\n",
    "        # Process each LLM actor\n",
    "        for actor in actors:\n",
    "            if actor == \"redditor\":\n",
    "                continue\n",
    "\n",
    "            # Get all available reasoning types for this actor\n",
    "            for reason_type in reason_types:\n",
    "                col_name = f\"{actor}_{reason_type}_embedding\"\n",
    "                if col_name not in embeddings_dict:\n",
    "                    continue\n",
    "\n",
    "                llm_embeddings = embeddings_dict[col_name]\n",
    "\n",
    "                # Compare each scenario\n",
    "                for scenario_idx in range(n_scenarios):\n",
    "                    llm_emb = llm_embeddings[scenario_idx].reshape(1, -1)\n",
    "                    human_emb = human_embeddings[scenario_idx].reshape(1, -1)\n",
    "\n",
    "                    llm_emb_norm = normalize(llm_emb, norm=\"l2\")\n",
    "                    human_emb_norm = normalize(human_emb, norm=\"l2\")\n",
    "\n",
    "                    similarity = cosine_similarity(llm_emb_norm, human_emb_norm)[0, 0]\n",
    "\n",
    "                    results.append(\n",
    "                        {\n",
    "                            \"actor1\": f\"{actor}_{reason_type}\",\n",
    "                            \"actor2\": \"human\",\n",
    "                            \"language\": language_code,\n",
    "                            \"similarity\": float(similarity),\n",
    "                            \"scenario_idx\": scenario_idx,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c81b38d-6eaa-45ad-acae-3b3288422ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "all_embeddings = {\n",
    "    \"Base\": load_embeddings(\"../data/embeddings.csv\"),\n",
    "    \"Portuguese\": load_embeddings(\"../data/embeddings_br.csv\"),\n",
    "    \"German\": load_embeddings(\"../data/embeddings_de.csv\"),\n",
    "    \"Spanish\": load_embeddings(\"../data/embeddings_es.csv\"),\n",
    "    \"French\": load_embeddings(\"../data/embeddings_fr.csv\"),\n",
    "}\n",
    "\n",
    "language_codes = [\"Base\", \"Portuguese\", \"German\", \"Spanish\", \"French\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82edb2ec-14b4-44c8-882f-d05f52f95587",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing languages: 100%|██████████| 5/5 [00:42<00:00,  8.48s/it]\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "# Extract all LLM vs human similarities\n",
    "df_anova = extract_llm_human_similarities_for_anova(all_embeddings, language_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6077175-19da-4b31-8f6a-82232f68107b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "\n",
    "# Save the data\n",
    "output_file = \"../results/anova_data.csv\"\n",
    "df_anova.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527bc14a-b5ff-4c85-9574-60999db552c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DESCRIPTIVE STATISTICS ===\n",
      "\n",
      "By Actor (LLM + reasoning type):\n",
      "                    count      mean       std       min       25%       50%  \\\n",
      "actor1                                                                        \n",
      "bison_reason_1    10806.0  0.468715  0.172539 -0.113236  0.354980  0.482823   \n",
      "bison_reason_2    10806.0  0.468603  0.171504 -0.089466  0.352683  0.483204   \n",
      "bison_reason_3    10806.0  0.468608  0.171439 -0.122836  0.354023  0.482802   \n",
      "claude_reason_1   12197.0  0.443336  0.148981 -0.093526  0.343479  0.457004   \n",
      "claude_reason_2   12197.0  0.443532  0.149045 -0.081075  0.343165  0.457342   \n",
      "claude_reason_3   10806.0  0.444976  0.149595 -0.064444  0.345770  0.459301   \n",
      "gemini_reason_1    1391.0  0.420860  0.137378  0.010950  0.319416  0.431945   \n",
      "gemini_reason_2    1391.0  0.419289  0.138878 -0.026329  0.311234  0.428001   \n",
      "gemma_reason_1    12197.0  0.402712  0.147288 -0.086656  0.302422  0.410749   \n",
      "gemma_reason_2    12197.0  0.404031  0.148104 -0.123496  0.305200  0.412743   \n",
      "gemma_reason_3    10806.0  0.407718  0.148682 -0.108808  0.305841  0.415184   \n",
      "gemma_reason_4    10806.0  0.424807  0.145814 -0.096856  0.327165  0.431683   \n",
      "gemma_reason_5    10806.0  0.424267  0.144992 -0.087433  0.326035  0.433587   \n",
      "gpt3.5_reason_1   12197.0  0.431885  0.151146 -0.150824  0.327916  0.440746   \n",
      "gpt3.5_reason_2   12197.0  0.430878  0.151992 -0.151601  0.326454  0.439784   \n",
      "gpt3.5_reason_3   10806.0  0.432520  0.153906 -0.157070  0.330034  0.442691   \n",
      "gpt4_reason_1     12197.0  0.449160  0.160639 -0.108893  0.340995  0.461230   \n",
      "gpt4_reason_2     12197.0  0.450236  0.161527 -0.112287  0.340183  0.461673   \n",
      "llama_reason_1    12197.0  0.388032  0.177333 -0.193726  0.278095  0.412471   \n",
      "llama_reason_2    12197.0  0.389416  0.177486 -0.155702  0.280519  0.411534   \n",
      "llama_reason_3    10806.0  0.420735  0.146962 -0.093853  0.321829  0.432930   \n",
      "mistral_reason_1  12197.0  0.386096  0.161451 -0.131123  0.276457  0.395931   \n",
      "mistral_reason_2  12197.0  0.386922  0.161281 -0.125885  0.277444  0.398663   \n",
      "mistral_reason_3  10806.0  0.400296  0.151985 -0.105694  0.294937  0.407714   \n",
      "\n",
      "                       75%       max  \n",
      "actor1                                \n",
      "bison_reason_1    0.597408  0.922024  \n",
      "bison_reason_2    0.597095  0.925996  \n",
      "bison_reason_3    0.595387  0.892138  \n",
      "claude_reason_1   0.552474  0.840129  \n",
      "claude_reason_2   0.552609  0.884231  \n",
      "claude_reason_3   0.554671  0.864394  \n",
      "gemini_reason_1   0.520198  0.769867  \n",
      "gemini_reason_2   0.520613  0.760780  \n",
      "gemma_reason_1    0.507819  0.841023  \n",
      "gemma_reason_2    0.509174  0.811027  \n",
      "gemma_reason_3    0.515929  0.837169  \n",
      "gemma_reason_4    0.530618  0.825283  \n",
      "gemma_reason_5    0.529511  0.818885  \n",
      "gpt3.5_reason_1   0.543927  0.856202  \n",
      "gpt3.5_reason_2   0.543428  0.874765  \n",
      "gpt3.5_reason_3   0.547458  0.870294  \n",
      "gpt4_reason_1     0.565878  0.893168  \n",
      "gpt4_reason_2     0.567468  0.904920  \n",
      "llama_reason_1    0.518561  0.852901  \n",
      "llama_reason_2    0.521224  0.848573  \n",
      "llama_reason_3    0.528019  0.837645  \n",
      "mistral_reason_1  0.504391  0.844393  \n",
      "mistral_reason_2  0.504122  0.856723  \n",
      "mistral_reason_3  0.511486  0.813189  \n",
      "\n",
      "By Language:\n",
      "               count      mean       std       min       25%       50%  \\\n",
      "language                                                                 \n",
      "Base        237732.0  0.430962  0.155889 -0.157070  0.325781  0.440278   \n",
      "French        5922.0  0.367728  0.172734 -0.155702  0.292618  0.407512   \n",
      "German        7224.0  0.248170  0.143811 -0.193726  0.165150  0.262624   \n",
      "Portuguese    4620.0  0.472199  0.158918 -0.093318  0.414441  0.504718   \n",
      "Spanish       1708.0  0.440235  0.175706 -0.125831  0.379250  0.476934   \n",
      "\n",
      "                 75%       max  \n",
      "language                        \n",
      "Base        0.544205  0.925996  \n",
      "French      0.485269  0.781536  \n",
      "German      0.342914  0.711157  \n",
      "Portuguese  0.576813  0.814004  \n",
      "Spanish     0.555765  0.820394  \n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\n=== DESCRIPTIVE STATISTICS ===\")\n",
    "print(\"\\nBy Actor (LLM + reasoning type):\")\n",
    "print(df_anova.groupby(\"actor1\")[\"similarity\"].describe())\n",
    "\n",
    "print(\"\\nBy Language:\")\n",
    "print(df_anova.groupby(\"language\")[\"similarity\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e12d717-814f-46ad-9a6d-fd2973ada8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ONE-WAY ANOVA: Comparing Actors ===\n",
      "F-statistic: 317.7166\n",
      "p-value: 0.0000e+00\n",
      "Result: Significant differences exist between actors (p < 0.05)\n",
      "\n",
      "Statsmodels:\n",
      "                sum_sq        df           F  PR(>F)\n",
      "C(actor1)   180.608452      23.0  317.716596     0.0\n",
      "Residual   6356.395381  257182.0         NaN     NaN\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "# Perform One-Way ANOVA for actors\n",
    "print(\"\\n=== ONE-WAY ANOVA: Comparing Actors ===\")\n",
    "actor_groups = [\n",
    "    group[\"similarity\"].values for name, group in df_anova.groupby(\"actor1\")\n",
    "]\n",
    "f_stat_actor, p_value_actor = stats.f_oneway(*actor_groups)\n",
    "print(f\"F-statistic: {f_stat_actor:.4f}\")\n",
    "print(f\"p-value: {p_value_actor:.4e}\")\n",
    "if p_value_actor < 0.05:\n",
    "    print(\"Result: Significant differences exist between actors (p < 0.05)\")\n",
    "else:\n",
    "    print(\"Result: No significant differences between actors (p >= 0.05)\")\n",
    "\n",
    "print(\"\\nStatsmodels:\")\n",
    "actor_model = ols(\"similarity ~ C(actor1)\", data=df_anova).fit()\n",
    "actor_anova_table = anova_lm(actor_model, typ=2)\n",
    "print(actor_anova_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6c8f22-c117-4405-a749-a0b6b87c16bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ONE-WAY ANOVA: Comparing Languages ===\n",
      "F-statistic: 2710.8010\n",
      "p-value: 0.0000e+00\n",
      "Result: Significant differences exist between languages (p < 0.05)\n",
      "\n",
      "Statsmodels:\n",
      "                  sum_sq        df            F  PR(>F)\n",
      "C(language)   264.441706       4.0  2710.801022     0.0\n",
      "Residual     6272.562127  257201.0          NaN     NaN\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "# Perform One-Way ANOVA for languages\n",
    "print(\"\\n=== ONE-WAY ANOVA: Comparing Languages ===\")\n",
    "language_groups = [\n",
    "    group[\"similarity\"].values for name, group in df_anova.groupby(\"language\")\n",
    "]\n",
    "f_stat_lang, p_value_lang = stats.f_oneway(*language_groups)\n",
    "print(f\"F-statistic: {f_stat_lang:.4f}\")\n",
    "print(f\"p-value: {p_value_lang:.4e}\")\n",
    "if p_value_lang < 0.05:\n",
    "    print(\"Result: Significant differences exist between languages (p < 0.05)\")\n",
    "else:\n",
    "    print(\"Result: No significant differences between languages (p >= 0.05)\")\n",
    "\n",
    "print(\"\\nStatsmodels:\")\n",
    "language_model = ols(\"similarity ~ C(language)\", data=df_anova).fit()\n",
    "language_anova_table = anova_lm(language_model, typ=2)\n",
    "print(language_anova_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a0ffca-2bc9-41fd-a1eb-471a17d1df30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TWO-WAY ANOVA: Actor × Language ===\n",
      "                             sum_sq        df             F    PR(>F)\n",
      "C(actor1)              7.318789e-08      23.0  1.377462e-07  1.000000\n",
      "C(language)            1.116527e-09       4.0  1.208308e-08  0.999912\n",
      "C(actor1):C(language)  6.014597e-01      92.0  2.830003e-01  0.989146\n",
      "Residual               5.939928e+03  257128.0           NaN       NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielhuf/Documents/PUC/puc-projeto-final/venv/lib/python3.12/site-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 23, but rank is 14\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/Users/danielhuf/Documents/PUC/puc-projeto-final/venv/lib/python3.12/site-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 4, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/Users/danielhuf/Documents/PUC/puc-projeto-final/venv/lib/python3.12/site-packages/statsmodels/base/model.py:1894: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 92, but rank is 11\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "# Two-Way ANOVA using statsmodels (if available)\n",
    "print(\"\\n=== TWO-WAY ANOVA: Actor × Language ===\")\n",
    "model = ols(\n",
    "    \"similarity ~ C(actor1) + C(language) + C(actor1):C(language)\", data=df_anova\n",
    ").fit()\n",
    "anova_table = anova_lm(model, typ=2)\n",
    "print(anova_table)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
